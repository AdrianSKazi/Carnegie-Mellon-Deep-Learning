{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6ad201de008d207bae0db1d182f6a661",
     "grade": false,
     "grade_id": "cell-eda6713e0fed77df",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Assignment 2 Part A - Convolutional Neural Networks\n",
    "\n",
    "Welcome to the second assignment!\n",
    "\n",
    "- This assignment is shorter\n",
    "    - There are only two questions (implementing `Conv1d`)\n",
    "    - We did this to give you more time for training in part B. Big computer vision models!\n",
    "\n",
    "Before we jump into the code, let's try to understand convolutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6bf6bc47ae21698039ede25efd20907b",
     "grade": false,
     "grade_id": "cell-330ab33b728f3c87",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Section 1: Introduction to 1D Convolutional Layers\n",
    "Of course, we already cover convolutions in lecture, but for your convenience/understanding, this notebook will provide an alternate explanation with examples directly relevant to the questions.\n",
    "\n",
    "Feel free to skip to the coding if you already understand convolutions well. We provide pseudocode there if you need it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "965a8212f26adf3871abefefe4ec26fb",
     "grade": false,
     "grade_id": "cell-58c38bb8618a72b8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1.1: Problem Motivation\n",
    "\n",
    "- Convolutions are great for problems that have **close-range relationships** between positions in your input.\n",
    "- Most popular application of convolutions is 2D convolutions for image processing tasks\n",
    "    - For images, the close-range relationships are between pixel positions (x coordinate and y coordinate). In other words, pixels that are near each other tend to be related in some significant way.\n",
    "- But convolutions are also used for 1-dimensional applications\n",
    "    - Examples: Audio-processing or stock price prediction\n",
    "\n",
    "In this assignment, you'll be implementing a 1D convolutional layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5be1ba32d17539b15c52b01382321e03",
     "grade": false,
     "grade_id": "cell-b21487d59704e91c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1.2: A Conceptual Intro to 1D Convolutions\n",
    "\n",
    "So what are convolutions and how do they capture close-range relationships?\n",
    "\n",
    "The most intuitive visualization of them is by visualizing a sliding window.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"images/spectrogram.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "Imagine you're given this input; a spectrogram just like the ones in part B of the first assignment. It's shaped `(num_frames, num_channels)`.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"images/spectrogram_animation.gif\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "**Explanation**:\n",
    "- We move the weight matrix ('kernel') along the input, and performing a `tensordot` (inner product) each time we move it\n",
    "- We move a fixed distance every time.\n",
    "    - This distance is called our **stride**\n",
    "- We then concatenate the outputs together to get a final output.\n",
    "\n",
    "**Main Idea**:\n",
    "\n",
    "By using a sliding window, a convolutional layer **captures the short-distance relationships between each snippet of the input that the kernel sees**. The weights will ideally end up learning what to bring out in these short-distance relationships for downstream layers to process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8b5841b353251d02bef4ae77673270d7",
     "grade": false,
     "grade_id": "cell-ea4b26a3ad1caea8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1.3: A Detailed Intro to Convolutions\n",
    "\n",
    "Now for a concrete example.\n",
    "\n",
    "Let's begin by introducing the input data and our parameters.\n",
    "\n",
    "### 1.3.1: Input Data:\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"images/input.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "Our input is a batch of two 2D matrices. You can imagine each horizontal slice (member of the batch) being a single spectrogram. Assume for now that every spectrogram is the same size so we can easily stack them into a batch.\n",
    "\n",
    "You can also interpret `input_size` as the time dimension, which will be true in many applications of `Conv1d` but not all.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3.2: Convolutional Layer\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"images/conv1d.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "Our `Conv1d` layer has a weight matrix and bias vector, just like a `Linear` layer. The weight matrix is our kernel. For convolutions, we use the terms \"weights\" or \"kernels\" interchangably.\n",
    "\n",
    "**Notice the params we initialized the layer with:**\n",
    "\n",
    "- `in_channels` is predetermined (based on how many channels our given input has)\n",
    "- We choose the rest:\n",
    "    - We choose `out_channels` based on intuition about how much complexity from the input's `in_channels` we want to isolate/preserve.\n",
    "    - We choose `kernel_size` based on how close-range the relationships are.\n",
    "        - The larger the kernel, the longer-range relationships you can encode (with caveats).\n",
    "    - We choose `stride` based on how much overlap we want between outputs.\n",
    "        - If `stride < kernel_size`, we'll end up processing some parts of the input multiple times (which is often a good thing).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6df896c9df445f5e1a6010b190e228ff",
     "grade": false,
     "grade_id": "cell-7401c25b62d929f4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.3.3: The Algorithm\n",
    "\n",
    "Now that we've covered the input and parameters, let's now cover how they're used.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"images/step_1.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "Just like our simple example above, we start at the beginning of the input and take a small slice to multiply against our kernel.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"images/conv_details.png\" width=\"800\"/>\n",
    "</div>\n",
    "\n",
    "We [`tensordot`](https://numpy.org/doc/stable/reference/generated/numpy.tensordot.html) (similar to a `matmul`, see appendix for some more details) along the **last two axes of our kernel and input slice** (`(in_channels, kernel_size)` for both). We then add the bias vector to the result, and then store it, just like in our simple example.\n",
    "\n",
    "We then `stride=2` units over and repeat this process to get our final output.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"images/conv_animation.gif\" width=\"800\"/>\n",
    "</div>\n",
    "\n",
    "Notice that we only stride until the kernel no longer fits onto the input.\n",
    "\n",
    "In other words, **because of how we chose our parameters, `Conv1d` ignores the very last frame of this input**.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"images/last_step.png\" width=\"450\"/>\n",
    "</div>\n",
    "\n",
    "This only ever happens at the edges of your input (borders of an image, last few frames of an audio clip). We try to avoid this by either tuning our parameters or by **padding** zeroes to the edges of the input (which we won't get into for now).\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"images/processed_twice.png\" width=\"450\"/>\n",
    "</div>\n",
    "\n",
    "Also, note that these two slices at index 2 and 5 were seen by the kernel twice. Again, this is usually not a bad thing, and is often done intentionally. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "22579ff5764f1cd12895505dbfee0be7",
     "grade": false,
     "grade_id": "cell-2fc732c0a56acfc8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.3.4: Calculating Output Size\n",
    "Last note: when moving the kernel along, you *could* implement this by iterating until the kernel no longer fits (probably using a `while` loop until some `break` condition), but `while` loops can be hard to debug and aren't easily parallelizable.\n",
    "\n",
    "Instead, you can actually **calculate how many output slices you'll generate and just iterate for exactly that many slices**.\n",
    "\n",
    "Here's the formula to figure out how many output slices you'll end up with:\n",
    "\n",
    "$$\\begin{align*}\n",
    "    \\text{output\\_size} = \\left \\lfloor{\\frac{\\text{input\\_size} - \\text{kernel\\_size}}{\\text{stride}}}\\right \\rfloor + 1\n",
    "\\end{align*}$$\n",
    "\n",
    "$$\\begin{align*}\n",
    "    &\\text{Where $\\left \\lfloor{x}\\right \\rfloor$ is the floor function (i.e. round down) applied to some float $x$}\n",
    "\\end{align*}$$\n",
    "\n",
    "So in this case, our `output_size=4`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "28c2c1ea29072bd3eb4d35c1c6db4ab9",
     "grade": false,
     "grade_id": "cell-fd9bde5c444e59f6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1.4: Summary\n",
    "\n",
    "Given an input, for each slice defined by the stride a `Conv1d` layer takes the inner products between the weights and the slice, and then adds the biases.\n",
    "\n",
    "- The size of each slice is determined by the `kernel_size`\n",
    "- The location of the beginning of the next slice is determined by the `stride`\n",
    "- The number of slices is determined by the `input_size`, the `kernel_size`, and `stride`, in the formula above.\n",
    "\n",
    "That's it! To save you time, we'll give you pseudocode for tackling this below, although ideally you should try to implement this based on your own understanding of the intro.\n",
    "\n",
    "**Make sure to run the cell below to import things!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to run this cell without modifying anything in it!\n",
    "import numpy as np\n",
    "\n",
    "# Import the code in `mytorch/nn.py`\n",
    "from mytorch import nn\n",
    "\n",
    "# These iPython functions make it so imported code is automatically reimported here if they are changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b329f75629bea66118d5e13438d8427c",
     "grade": false,
     "grade_id": "cell-05e79718719dc398",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 1: `Conv1d.forward()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c42e3e425720fa38548da7eaf2edc504",
     "grade": false,
     "grade_id": "cell-a636d0d5d7c9e9bd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Finally, we can begin coding. Make sure to load in the imports in the previous cell.\n",
    "\n",
    "**First**, in `mytorch/nn.py`, complete `get_conv1d_output_size()` using the formula in Section 1.3.4 of this notebook. Should just be one line of code.\n",
    "\n",
    "**Second**, in `mytorch/nn.py`, complete `Conv1d.forward()` using the pseudocode below.\n",
    "\n",
    "\n",
    "**Pseudocode**\n",
    "\n",
    "- Pre-calculate and store the number of output slices\n",
    "- Pre-declare an output array filled with zeros, shaped `(batch_size, out_channels, output_size)`\n",
    "    - This is where we'll store the results of each `tensordot`\n",
    "- For each output slice to calculate:\n",
    "    - Determine the beginning/end index of the current input slice\n",
    "        - Hint: `beg_index = i * stride`, what is `end_index`?\n",
    "    - Do a `tensordot` between the weight matrix and the 2nd/3rd axes of the input\n",
    "    - Add the bias to the result\n",
    "    - Store the result in the appropriate slice of the output array (hint: index along the last axis of `out`)\n",
    "- Return the output array\n",
    "\n",
    "Done. Hopefully it's clear how the above pseudocode accomplishes everything we discuss in our long intro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  6.,  -3.,  -2.],\n",
       "        [ -5.,   1., -13.],\n",
       "        [ -6.,  28., -11.]],\n",
       "\n",
       "       [[  6., -16.,  16.],\n",
       "        [ 27.,  35., -21.],\n",
       "        [  2.,  12., -22.]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_conv1d_forward_1(Conv1d):\n",
    "    # Same params as in the introduction\n",
    "    in_channels = 2\n",
    "    out_channels = 3\n",
    "    kernel_size = 2\n",
    "    stride = 1\n",
    "\n",
    "    # Declare layer, weights, and biases (values initialized to increasing integers for consistency)\n",
    "    layer = Conv1d(in_channels, out_channels, kernel_size, stride)\n",
    "    layer.weight = np.array([[[0, 1],\n",
    "                              [2, 3]],\n",
    "\n",
    "                             [[4, 2],\n",
    "                              [-2, -4]],\n",
    "\n",
    "                             [[3, -4],\n",
    "                              [5, 2]]])\n",
    "\n",
    "    layer.bias = np.array([0, 1, 2])\n",
    "\n",
    "    # Declare example input (increasing integers)\n",
    "    batch_size = 2\n",
    "    input_size = 4\n",
    "\n",
    "    #batch, in_ch, input\n",
    "    x = np.array([[[0, 1, -3, -1],\n",
    "                   [-2, 3, -2, 1]], \n",
    "\n",
    "                  [[4, 5, -2, 3],\n",
    "                   [2, -1, -4, 7]]])\n",
    "\n",
    "    out = layer.forward(x)\n",
    "    return out\n",
    "\n",
    "\n",
    "test_conv1d_forward_1(nn.Conv1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests import test_conv1d_forward_1, test_conv1d_forward_2, test_conv1d_forward_3\n",
    "\n",
    "answer_1 = test_conv1d_forward_1(nn.Conv1d)\n",
    "answer_2 = test_conv1d_forward_2(nn.Conv1d)\n",
    "answer_3 = test_conv1d_forward_3(nn.Conv1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  6.,  -3.,  -2.],\n",
       "        [ -5.,   1., -13.],\n",
       "        [ -6.,  28., -11.]],\n",
       "\n",
       "       [[  6., -16.,  16.],\n",
       "        [ 27.,  35., -21.],\n",
       "        [  2.,  12., -22.]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  4324.],\n",
       "        [ 10949.],\n",
       "        [ 17574.],\n",
       "        [ 24199.],\n",
       "        [ 30824.]],\n",
       "\n",
       "       [[ 10948.],\n",
       "        [ 31397.],\n",
       "        [ 51846.],\n",
       "        [ 72295.],\n",
       "        [ 92744.]],\n",
       "\n",
       "       [[ 17572.],\n",
       "        [ 51845.],\n",
       "        [ 86118.],\n",
       "        [120391.],\n",
       "        [154664.]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -225. ,  -252.5,  -280. ,  -307.5,  -335. ],\n",
       "        [   26. ,    23.5,    21. ,    18.5,    16. ],\n",
       "        [  277. ,   299.5,   322. ,   344.5,   367. ]],\n",
       "\n",
       "       [[ -912.5,  -940. ,  -967.5,  -995. , -1022.5],\n",
       "        [  -36.5,   -39. ,   -41.5,   -44. ,   -46.5],\n",
       "        [  839.5,   862. ,   884.5,   907. ,   929.5]],\n",
       "\n",
       "       [[-1600. , -1627.5, -1655. , -1682.5, -1710. ],\n",
       "        [  -99. ,  -101.5,  -104. ,  -106.5,  -109. ],\n",
       "        [ 1402. ,  1424.5,  1447. ,  1469.5,  1492. ]],\n",
       "\n",
       "       [[-2287.5, -2315. , -2342.5, -2370. , -2397.5],\n",
       "        [ -161.5,  -164. ,  -166.5,  -169. ,  -171.5],\n",
       "        [ 1964.5,  1987. ,  2009.5,  2032. ,  2054.5]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dce44df46e61857dae0d6a1daa93ef29",
     "grade": true,
     "grade_id": "cell-eaf2b51d5fe4f68d",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Run this cell to evaluate your code on all three unit tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3f0ab8643f2059f30b08ac30b16e3ead",
     "grade": false,
     "grade_id": "cell-c2e43caed504f644",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "If you passed the tests above, assign the string \"Question 1 passed\" to asn1 in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "65a663a3815a7dcc70050b745135b661",
     "grade": false,
     "grade_id": "cell-649c8bcd8b0be379",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "ans1 = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "ans1 = \"Question 1 passed\"\n",
    "asn1 = \"Question 1 passed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e6c09d86ff0cb2103429357adc749a5d",
     "grade": true,
     "grade_id": "cell-a038bac774b990da",
     "locked": true,
     "points": 50,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3c1f90d3ebf08c26c58bc2b468ebd0b1",
     "grade": false,
     "grade_id": "cell-b223d45df70c1620",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Section 2: `Conv1d.backward()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "678e8f450005659cb9f81cd5e9bdc5b0",
     "grade": false,
     "grade_id": "cell-e2582787c38abcdd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 2.1: Problem Motivation\n",
    "\n",
    "Backprop for `Conv1d` is a little harder than it was for `Linear`.\n",
    "\n",
    "Remember that the purpose of backprop is to determine how each parameter (weights and biases) affected the loss. We also calculate the gradient w.r.t. the input, in order to pass it along to earlier layers in the network.\n",
    "\n",
    "The challenge comes from the fact that our weight tensor was used multiple times - each time it slid along the input and did a `tensordot`, its params affected the output at that part. So we need to calculate and sum up the influence of each param every time it was used.\n",
    "\n",
    "**In summary**, just like `Linear.backward()`, the goal of `Conv1d.backward()` is to figure out how the params affected the loss and also pass the gradient w.r.t. the input backwards. This gets complicated because our params were used multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1bd77772a60f83eecb253b9c1795f6f3",
     "grade": false,
     "grade_id": "cell-dbc8d55bac8c2213",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 2.2: A Note\n",
    "\n",
    "Instead of creating a detailed explanation in this notebook like we did for `Conv1d.forward()`, we've decided to just provide pseudocode.\n",
    "\n",
    "We do this because:\n",
    "1. An extensive conceptual explanation is already given in lecture\n",
    "2. The explanation is pretty technical and explaining it again here doesn't really add much\n",
    "    - The main takeaway is what we describe in the summary above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5c81192933c247c6f8ffc280a19f0605",
     "grade": false,
     "grade_id": "cell-2f6cbec7481a40a3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 2: `Conv1d.backward()`\n",
    "\n",
    "\n",
    "In `mytorch/nn.py`, complete `Conv1d.backward()`.\n",
    "\n",
    "This will involve:\n",
    "\n",
    "1. Iteratively calculating and `return`ing `dx`\n",
    "2. Iteratively calculating and storing `grad_weight`\n",
    "3. Calculating and storing `grad_bias`\n",
    "\n",
    "Pseudocode:\n",
    "- Make array filled with 0's, the same shape as the original input `x`\n",
    "- For each slice in the number of output slices:\n",
    "    - Calculate the beginning/end index of our current slice, exactly like we did in `forward()`\n",
    "    - Add to `dx[:,:,b:e]` using the `+=` operator:  \n",
    "        - `tensordot` between `delta[:,:,i]` and `self.weight` along `axes=(1)`\n",
    "        - In other words, we're accumulating the influence of slice `i` of the output on indices `[b:e]` of the input. We use a `+=` because some slices of the input may have been used multiple times, so we just sum up their influences\n",
    "    - Add to `self.grad_weight` using the `+=` operator:\n",
    "        - `tensordot` between `delta[:,:,i].T` and `self.x[:,:,b:e]` along `axes=(1)`\n",
    "        - We add to the entire weight's gradient because the entire kernel was used for this slice\n",
    "        - Again, it's `+=` because the kernel possibly saw parts of the input multiple times, so we just sum up its total influence on those parts\n",
    "- We can calculate the bias's gradient in one line of code:\n",
    "    - Set `self.grad_bias` equal to the sum of `delta` along axes `(0,2)`\n",
    "    - This works because the bias affected each part of the output the same way, so we just need its total influence.\n",
    "\n",
    "Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 14.,  -4.,   2.,   1.],\n",
       "         [ 10.,  14.,   6., -13.]],\n",
       " \n",
       "        [[ 32.,  21., -12., -13.],\n",
       "         [ 36.,  29.,  -8.,  -1.]]]), array([[[  8.,  -3.],\n",
       "         [  7., -14.]],\n",
       " \n",
       "        [[ 34.,  -2.],\n",
       "         [-15., -24.]],\n",
       " \n",
       "        [[ 62.,  27.],\n",
       "         [  1., -19.]]]), array([-3, 11, 22]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_conv1d_backward_1(Conv1d):\n",
    "    # Same params as in the introduction\n",
    "    in_channels = 2\n",
    "    out_channels = 3\n",
    "    kernel_size = 2\n",
    "    stride = 1\n",
    "\n",
    "    # Declare layer, weights, and biases (values initialized to increasing integers for consistency)\n",
    "    layer = Conv1d(in_channels, out_channels, kernel_size, stride)\n",
    "    layer.weight = np.array([[[0, 1],\n",
    "                              [2, 3]],\n",
    "\n",
    "                             [[4, 2],\n",
    "                              [-2, -4]],\n",
    "\n",
    "                             [[3, -4],\n",
    "                              [5, 2]]])\n",
    "    layer.bias = np.array([0, 1, 2])\n",
    "\n",
    "    # Declare example input\n",
    "    batch_size = 2\n",
    "    input_size = 4\n",
    "\n",
    "    # Run the forward pass\n",
    "    x = np.array([[[0, 1, -3, -1],\n",
    "                   [-2, 3, -2, 1]], \n",
    "\n",
    "                  [[4, 5, -2, 3],\n",
    "                   [2, -1, -4, 7]]])\n",
    "    layer.forward(x)\n",
    "\n",
    "    # Make up a gradient of loss w.r.t. output of this layer \n",
    "    delta = np.array([[[2, -1, -1],\n",
    "                       [2, -2, 3],\n",
    "                       [2, 2, 1]],\n",
    "\n",
    "                      [[-0, 0, -3],\n",
    "                       [2, 7, -1],\n",
    "                       [8, 7, 2]]])\n",
    "\n",
    "    grad_x = layer.backward(delta)\n",
    "\n",
    "    return grad_x, layer.grad_weight, layer.grad_bias\n",
    "\n",
    "test_conv1d_backward_1(nn.Conv1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests import test_conv1d_backward_1, test_conv1d_backward_2, test_conv1d_backward_3\n",
    "\n",
    "answer_1 = test_conv1d_backward_1(nn.Conv1d)\n",
    "answer_2 = test_conv1d_backward_2(nn.Conv1d)\n",
    "answer_3 = test_conv1d_backward_3(nn.Conv1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7dbc601fe4cafb5f9d376857f5181fbe",
     "grade": true,
     "grade_id": "cell-91c16c3947535409",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 14.,  -4.,   2.,   1.],\n",
       "         [ 10.,  14.,   6., -13.]],\n",
       " \n",
       "        [[ 32.,  21., -12., -13.],\n",
       "         [ 36.,  29.,  -8.,  -1.]]]), array([[[  8.,  -3.],\n",
       "         [  7., -14.]],\n",
       " \n",
       "        [[ 34.,  -2.],\n",
       "         [-15., -24.]],\n",
       " \n",
       "        [[ 62.,  27.],\n",
       "         [  1., -19.]]]), array([-3, 11, 22]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 720.,  730.,  740.,  750.,  760.,  770.,  780.,  790.],\n",
       "         [ 800.,  810.,  820.,  830.,  840.,  850.,  860.,  870.],\n",
       "         [ 880.,  890.,  900.,  910.,  920.,  930.,  940.,  950.]],\n",
       " \n",
       "        [[1920., 1955., 1990., 2025., 2060., 2095., 2130., 2165.],\n",
       "         [2200., 2235., 2270., 2305., 2340., 2375., 2410., 2445.],\n",
       "         [2480., 2515., 2550., 2585., 2620., 2655., 2690., 2725.]],\n",
       " \n",
       "        [[3120., 3180., 3240., 3300., 3360., 3420., 3480., 3540.],\n",
       "         [3600., 3660., 3720., 3780., 3840., 3900., 3960., 4020.],\n",
       "         [4080., 4140., 4200., 4260., 4320., 4380., 4440., 4500.]]]),\n",
       " array([[[ 600.,  615.,  630.,  645.,  660.,  675.,  690.,  705.],\n",
       "         [ 720.,  735.,  750.,  765.,  780.,  795.,  810.,  825.],\n",
       "         [ 840.,  855.,  870.,  885.,  900.,  915.,  930.,  945.]],\n",
       " \n",
       "        [[ 672.,  690.,  708.,  726.,  744.,  762.,  780.,  798.],\n",
       "         [ 816.,  834.,  852.,  870.,  888.,  906.,  924.,  942.],\n",
       "         [ 960.,  978.,  996., 1014., 1032., 1050., 1068., 1086.]],\n",
       " \n",
       "        [[ 744.,  765.,  786.,  807.,  828.,  849.,  870.,  891.],\n",
       "         [ 912.,  933.,  954.,  975.,  996., 1017., 1038., 1059.],\n",
       "         [1080., 1101., 1122., 1143., 1164., 1185., 1206., 1227.]],\n",
       " \n",
       "        [[ 816.,  840.,  864.,  888.,  912.,  936.,  960.,  984.],\n",
       "         [1008., 1032., 1056., 1080., 1104., 1128., 1152., 1176.],\n",
       "         [1200., 1224., 1248., 1272., 1296., 1320., 1344., 1368.]],\n",
       " \n",
       "        [[ 888.,  915.,  942.,  969.,  996., 1023., 1050., 1077.],\n",
       "         [1104., 1131., 1158., 1185., 1212., 1239., 1266., 1293.],\n",
       "         [1320., 1347., 1374., 1401., 1428., 1455., 1482., 1509.]]]),\n",
       " array([15., 18., 21., 24., 27.], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[  12.5,    5. ,   -2.5,  -10. ,  -17.5],\n",
       "         [  27.5,   23. ,   18.5,   14. ,    9.5],\n",
       "         [  42.5,   41. ,   39.5,   38. ,   36.5],\n",
       "         [  57.5,   59. ,   60.5,   62. ,   63.5],\n",
       "         [  72.5,   77. ,   81.5,   86. ,   90.5]],\n",
       " \n",
       "        [[-100. , -107.5, -115. , -122.5, -130. ],\n",
       "         [ -40. ,  -44.5,  -49. ,  -53.5,  -58. ],\n",
       "         [  20. ,   18.5,   17. ,   15.5,   14. ],\n",
       "         [  80. ,   81.5,   83. ,   84.5,   86. ],\n",
       "         [ 140. ,  144.5,  149. ,  153.5,  158. ]],\n",
       " \n",
       "        [[-212.5, -220. , -227.5, -235. , -242.5],\n",
       "         [-107.5, -112. , -116.5, -121. , -125.5],\n",
       "         [  -2.5,   -4. ,   -5.5,   -7. ,   -8.5],\n",
       "         [ 102.5,  104. ,  105.5,  107. ,  108.5],\n",
       "         [ 207.5,  212. ,  216.5,  221. ,  225.5]],\n",
       " \n",
       "        [[-325. , -332.5, -340. , -347.5, -355. ],\n",
       "         [-175. , -179.5, -184. , -188.5, -193. ],\n",
       "         [ -25. ,  -26.5,  -28. ,  -29.5,  -31. ],\n",
       "         [ 125. ,  126.5,  128. ,  129.5,  131. ],\n",
       "         [ 275. ,  279.5,  284. ,  288.5,  293. ]]]), array([[[28770.],\n",
       "         [31220.],\n",
       "         [33670.],\n",
       "         [36120.],\n",
       "         [38570.]],\n",
       " \n",
       "        [[32720.],\n",
       "         [35670.],\n",
       "         [38620.],\n",
       "         [41570.],\n",
       "         [44520.]],\n",
       " \n",
       "        [[36670.],\n",
       "         [40120.],\n",
       "         [43570.],\n",
       "         [47020.],\n",
       "         [50470.]]]), array([490., 590., 690.], dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0481ec92b1cbf116bf7804f0471e5fa0",
     "grade": false,
     "grade_id": "cell-0fad510be6acd299",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "If you passed the tests above, assign the string \"Question 2 passed\" to asn2 in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d06c86ad2f461c3841c038622ce77d30",
     "grade": false,
     "grade_id": "cell-9d8c544916d52eb7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "ans2 = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "ans3 = 'Question 2 passed'\n",
    "asn3 = 'Question 2 passed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "da95e376789fd0b41a3839b3532731ab",
     "grade": true,
     "grade_id": "cell-a9dd4594db21c5f9",
     "locked": true,
     "points": 50,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "421b2c7c191e008915ae72fb4313a432",
     "grade": false,
     "grade_id": "cell-9e341db7f1245a77",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Appendix\n",
    "\n",
    "## `tensordot`\n",
    "\n",
    "[NumPy documentation](https://numpy.org/doc/stable/reference/generated/numpy.tensordot.html)\n",
    "\n",
    "Similar to dot products/matrix multiplication. \n",
    "\n",
    "Given two tensors $A$ and $B$ and an axis/axes you want to multiply across, we perform an element-wise multiplication along the desired axis/axes of the two tensors, then sum each of the products.\n",
    "\n",
    "In a sense, you 'eliminate' the axes you specify. So if you tensordot along the 2nd & 3rd axes of tensors shaped `(2, 4, 3)` and `(5, 4, 3)`, your output will be shaped `(2, 5)`; the first axes 'remaining' after eliminating the second and third axes of both tensors."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80e249822db5758e05c7a95f2378bda83bb74a36814d9a884ba3a875cd74994c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
